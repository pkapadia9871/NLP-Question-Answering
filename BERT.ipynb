{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80e6cba7",
   "metadata": {},
   "source": [
    "## Source Cited: <br> Natural Language Processing with TensorFlow - Second Edition <br> by Packt Publishing, Ch 10 (Transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba2b8fb",
   "metadata": {},
   "source": [
    "Load dataset SQUAD which we will use for the modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1debcd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b5d08fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? -> {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}\n",
      "What is in front of the Notre Dame Main Building? -> {'text': ['a copper statue of Christ'], 'answer_start': [188]}\n",
      "The Basilica of the Sacred heart at Notre Dame is beside to which structure? -> {'text': ['the Main Building'], 'answer_start': [279]}\n",
      "What is the Grotto at Notre Dame? -> {'text': ['a Marian place of prayer and reflection'], 'answer_start': [381]}\n",
      "What sits on top of the Main Building at Notre Dame? -> {'text': ['a golden statue of the Virgin Mary'], 'answer_start': [92]}\n"
     ]
    }
   ],
   "source": [
    "for q, a in zip(dataset[\"train\"][\"question\"][:5], dataset[\"train\"][\"answers\"][:5]):\n",
    "    print(f\"{q} -> {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62109060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data corrections\n",
      "\n",
      "Validation data correction\n"
     ]
    }
   ],
   "source": [
    "def compute_end_index(answers, contexts):\n",
    "    \"\"\" Add end index to answers \"\"\"\n",
    "    \n",
    "    fixed_answers = []\n",
    "    for answer, context in zip(answers, contexts):\n",
    "        gold_text = answer['text'][0]\n",
    "        answer['text'] = gold_text\n",
    "        start_idx = answer['answer_start'][0]\n",
    "        answer['answer_start'] = start_idx\n",
    "        \n",
    "        # Make sure the starting index is valid and there is an answer\n",
    "        assert start_idx >=0 and len(gold_text.strip()) > 0\n",
    "        \n",
    "        end_idx = start_idx + len(gold_text)        \n",
    "        answer['answer_end'] = end_idx\n",
    "        \n",
    "        # Make sure the corresponding context matches the actual answer\n",
    "        assert context[start_idx:end_idx] == gold_text\n",
    "        \n",
    "        fixed_answers.append(answer)\n",
    "    \n",
    "    return fixed_answers, contexts\n",
    "train_questions = dataset[\"train\"][\"question\"]\n",
    "print(\"Training data corrections\")\n",
    "train_answers, train_contexts = compute_end_index(\n",
    "    dataset[\"train\"][\"answers\"], dataset[\"train\"][\"context\"]\n",
    ")\n",
    "test_questions = dataset[\"validation\"][\"question\"]\n",
    "print(\"\\nValidation data correction\")\n",
    "test_answers, test_contexts = compute_end_index(\n",
    "    dataset[\"validation\"][\"answers\"], dataset[\"validation\"][\"context\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dc4136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09486be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"This is the context\"\n",
    "question = \"This is the question\"\n",
    "token_ids = tokenizer(\n",
    "    text=context, text_pair=question,\n",
    "padding=False, return_tensors='tf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "356a3973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode train data\n",
    "train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True, return_tensors='tf')\n",
    "# Encode test data\n",
    "test_encodings = tokenizer(test_contexts, test_questions, truncation=True, padding=True, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21cf5722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/87599 had answers truncated\n",
      "8/10570 had answers truncated\n"
     ]
    }
   ],
   "source": [
    "def replace_char_with_token_indices(encodings, answers):\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    n_updates = 0\n",
    "    # Go through all the answers\n",
    "    for i in range(len(answers)):\n",
    "        # Get the token position for both start end char positions\n",
    "        start_positions.append(encodings.char_to_token(i, \n",
    "        answers[i]['answer_start']))\n",
    "        end_positions.append(encodings.char_to_token(i, \n",
    "        answers[i]['answer_end'] - 1))\n",
    "        \n",
    "        if start_positions[-1] is None or end_positions[-1] is None:\n",
    "            n_updates += 1\n",
    "        # if start position is None, the answer passage has been truncated\n",
    "        # In the guide, https://huggingface.co/transformers/custom_\n",
    "        # datasets.html#qa-squad they set it to model_max_length, but\n",
    "        # this will result in NaN losses as the last available label is\n",
    "        # model_max_length-1 (zero-indexed)\n",
    "        if start_positions[-1] is None:\n",
    "            start_positions[-1] = tokenizer.model_max_length -1\n",
    "            \n",
    "        if end_positions[-1] is None:\n",
    "            end_positions[-1] = tokenizer.model_max_length -1\n",
    "            \n",
    "    print(\"{}/{} had answers truncated\".format(n_updates, \n",
    "    len(answers)))\n",
    "    encodings.update({'start_positions': start_positions, \n",
    "    'end_positions': end_positions})\n",
    "    \n",
    "replace_char_with_token_indices(train_encodings, train_answers)\n",
    "replace_char_with_token_indices(test_encodings, test_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57f9a2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(input_ids, attention_mask, start_positions, end_positions):\n",
    "    \"\"\" Generator for data \"\"\"\n",
    "    for inps, attn, start_pos, end_pos in zip(input_ids, \n",
    "    attention_mask, start_positions, end_positions):\n",
    "        yield (inps, attn), (start_pos, end_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb263177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "# Define the generator as a callable\n",
    "train_data_gen = partial(data_gen,\n",
    "    input_ids=train_encodings['input_ids'], \n",
    "    attention_mask=train_encodings['attention_mask'],\n",
    "    start_positions=train_encodings['start_positions'],\n",
    "    end_positions=train_encodings['end_positions']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6c63973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    train_data_gen, output_types=(('int32', 'int32'), ('int32', 'int32'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a3d1ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the data\n",
    "train_dataset = train_dataset.shuffle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "614cd984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid set is taken as the first 50 samples in the shuffled set\n",
    "valid_dataset = train_dataset.take(5)\n",
    "valid_dataset = valid_dataset.batch(1)\n",
    "# Rest is kept as the training data\n",
    "train_dataset = train_dataset.take(5)\n",
    "train_dataset = train_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ac6b22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test data\n"
     ]
    }
   ],
   "source": [
    "# Creating test data\n",
    "print(\"Creating test data\")\n",
    "# Define the generator as a callable\n",
    "test_data_gen = partial(data_gen,\n",
    "    input_ids=test_encodings['input_ids'], \n",
    "    attention_mask=test_encodings['attention_mask'],\n",
    "    start_positions=test_encodings['start_positions'], \n",
    "    end_positions=test_encodings['end_positions']\n",
    ")\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    test_data_gen, output_types=(('int32', 'int32'), ('int32', \n",
    "    'int32'))\n",
    ")\n",
    "test_dataset = test_dataset.batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4da9de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, TFBertForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bbc45dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained(\"bert-base-uncased\", return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "934d00f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForQuestionAnswering.from_pretrained(\"bert-base-uncased\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5037ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_wrap_model(model):\n",
    "    \"\"\" Wraps the huggingface's model with in the Keras Functional API \"\"\"\n",
    "    # Define inputs\n",
    "    input_ids = tf.keras.layers.Input([None,], dtype=tf.int32, \n",
    "    name=\"input_ids\")\n",
    "    attention_mask = tf.keras.layers.Input([None,], dtype=tf.int32, \n",
    "    name=\"attention_mask\")\n",
    "    \n",
    "    # Define the output (TFQuestionAnsweringModelOutput)\n",
    "    out = model([input_ids, attention_mask])\n",
    "    \n",
    "    # Get the correct attributes in the produced object to generate an\n",
    "    # output tuple\n",
    "    wrap_model = tf.keras.models.Model([input_ids, attention_mask], \n",
    "    #outputs=(out.start_logits, out.end_logits)\n",
    "    outputs=(out[0], out[1])\n",
    "    )\n",
    "    \n",
    "    return wrap_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b26f2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model_v2 = tf_wrap_model(model)\n",
    "model_v2.compile(optimizer=optimizer, loss=loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb6c51e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5/5 [==============================] - 103s 10s/step - loss: 12.8560 - tf_bert_for_question_answering_loss: 6.4659 - tf_bert_for_question_answering_1_loss: 6.3901 - tf_bert_for_question_answering_sparse_categorical_accuracy: 0.0000e+00 - tf_bert_for_question_answering_1_sparse_categorical_accuracy: 0.0000e+00 - val_loss: 12.4767 - val_tf_bert_for_question_answering_loss: 6.2383 - val_tf_bert_for_question_answering_1_loss: 6.2383 - val_tf_bert_for_question_answering_sparse_categorical_accuracy: 0.0000e+00 - val_tf_bert_for_question_answering_1_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/3\n",
      "5/5 [==============================] - 37s 8s/step - loss: 12.3882 - tf_bert_for_question_answering_loss: 6.1181 - tf_bert_for_question_answering_1_loss: 6.2701 - tf_bert_for_question_answering_sparse_categorical_accuracy: 0.0000e+00 - tf_bert_for_question_answering_1_sparse_categorical_accuracy: 0.0000e+00 - val_loss: 12.4766 - val_tf_bert_for_question_answering_loss: 6.2383 - val_tf_bert_for_question_answering_1_loss: 6.2383 - val_tf_bert_for_question_answering_sparse_categorical_accuracy: 0.0000e+00 - val_tf_bert_for_question_answering_1_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/3\n",
      "5/5 [==============================] - 41s 9s/step - loss: 12.9159 - tf_bert_for_question_answering_loss: 6.4821 - tf_bert_for_question_answering_1_loss: 6.4337 - tf_bert_for_question_answering_sparse_categorical_accuracy: 0.0000e+00 - tf_bert_for_question_answering_1_sparse_categorical_accuracy: 0.0000e+00 - val_loss: 12.4766 - val_tf_bert_for_question_answering_loss: 6.2383 - val_tf_bert_for_question_answering_1_loss: 6.2383 - val_tf_bert_for_question_answering_sparse_categorical_accuracy: 0.0000e+00 - val_tf_bert_for_question_answering_1_sparse_categorical_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c33d5f74f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_v2.fit(\n",
    "    train_dataset, \n",
    "    validation_data=valid_dataset,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Create folders\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "if not os.path.exists('tokenizers'):\n",
    "    os.makedirs('tokenizers')\n",
    "    \n",
    "# Save the model\n",
    "model_v2.get_layer(\"tf_bert_for_question_answering\").save_pretrained(os.path.join('models', 'bert_qa'))\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(os.path.join('tokenizers', 'bert_qa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52f5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
